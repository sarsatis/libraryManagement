Request GCS-Approved CIS Benchmark Data for Waivers Implementation

Description:
To implement waivers logic for Inspector 2 findings, we need an accurate and centralized list of GCS-approved CIS benchmark rules per platform. Current data in Confluence is inconsistent‚ÄîCIS IDs do not match across sources, and multiple Excel files exist for the same platforms with no clear versioning or filtering criteria.

This is blocking automation efforts to generate an accurate waivers.yaml file.

Platforms:

amazon_linux_2023

amazon_linux_2

microsoft_windows_server_2022

microsoft_windows_server_2019

rocky_rocky_linux_8

redhat_redhat_enterprise_linux_8.10

redhat_redhat_enterprise_linux_8.8

Acceptance Criteria:

A single, verified source of GCS-approved CIS IDs is provided per platform.

The data includes CIS ID, rule description, approval status, and platform.

The CIS IDs align with those used in Amazon Inspector 2 scan outputs.

Format is Excel, CSV, or a centrally maintained reference document.


---
Subject: Request for Clear and Accurate GCS-Approved CIS Data for Waivers Implementation

Hi Jack,

I hope you're doing well.

As part of the waivers functionality we're building, we are automating the process of validating Amazon Inspector 2 scan results against the GCS-approved CIS benchmark profiles. The goal is to mark any findings already approved by GCS as Skipped, regardless of their original status in Inspector 2, to reflect more accurate compliance reporting.

The logic to implement this is already in place, but I‚Äôm currently facing challenges in sourcing reliable and consistent data on which CIS profiles have been approved by GCS for the supported platforms:

amazon_linux_2023

amazon_linux_2

microsoft_windows_server_2022

microsoft_windows_server_2019

rocky_rocky_linux_8

redhat_redhat_enterprise_linux_8.10

redhat_redhat_enterprise_linux_8.8

When I initially started the analysis with Amazon Linux 2023, you mentioned during our sync to filter the ‚ÄúResponse for Amazon Linux 2023‚Äù column for ‚ÄúNA.‚Äù However, upon doing that and comparing the filtered entries to the actual CIS Benchmark v1.0.0 used by Inspector 2, I noticed several discrepancies.

For instance, GCS marks CIS ID 1.1.10 as approved, but in the Amazon CIS profile, the corresponding rule with the same description is 1.1.3.1. This mismatch in IDs while having matching descriptions makes the automated matching process unreliable. I have documented these discrepancies in the Confluence page.

Additionally, for the other platforms, there are multiple Excel files uploaded to Confluence for the same OS, with no clear indication of which one is the latest. Most of them also lack the "Response" columns used for filtering in the Amazon Linux case, making it difficult to extract a definitive list of GCS-approved CIS rules.

Given this situation, I would like to check:

Is there a single source of truth for the GCS-approved CIS IDs per platform?

If yes, could you please help point me to it or share the latest and most accurate data files?

Accurate data is critical for me to complete this task, which will output an updated waivers.yaml file listing all approved waiver IDs grouped by platform. This is essential to ensure downstream exemption processing is accurate.

Thanks so much for your help on this.

Best regards,
[Your Name]
----
# üìÑ CHANGELOG

## [1.0.0] - 2025-05-12

### ‚úÖ Added
- Initial project setup for `chf_data_ingestion`.
- Directory structure including `source/`, `output/`, `waivers.yaml`, and `playbooks/`.
- Ansible playbooks for each pipeline stage: `download.yml`, `transform.yml`, `waivers.yml`.
- Automated scheduling via Ansible Tower (Mondays at 09:00 AM London time).

### üöÄ New Features
- **Scan Report Download**: Connects to AWS Inspector 2 and pulls CIS benchmark scan reports in Excel format.
- **Data Transformation**: Cleans and converts Excel data to structured JSON.
- **Waiver Application**: Applies waivers based on `waivers.yaml` to mark findings as waived by platform and ID.
- **Splunk Integration**: Publishes the final JSON output to Splunk for compliance tracking.

### ‚úèÔ∏è Notable Changes
- Standardized JSON output format for interoperability with downstream tools.
- Introduced logical separation between raw, transformed, and waived data.

### ‚ö†Ô∏è Deprecation
- None in this release.

### ‚ùå Removals
- None in this release.


----
# üì¶ chf_data_ingestion

`chf_data_ingestion` is an automated pipeline for retrieving, processing, and publishing AWS Inspector 2 scan reports. This system supports CIS compliance validation and integrates waiver handling based on a centrally maintained `waivers.yaml` file. The processed data is finally sent to Splunk for monitoring and reporting.

---

## üîÑ Workflow Summary

The pipeline is divided into three main stages, executed via **Ansible** tasks:

### 1. üü° Download Scan Reports
- Connects to **AWS Inspector 2**.
- Downloads the latest **CIS benchmark scan reports** in Excel format.
- Saves the files in the `source/` directory.

### 2. üü¢ Transform and Clean Data
- Reads Excel files from `source/`.
- Cleans and converts them into structured **JSON files**.
- Outputs the result to the `output/` directory.

### 3. üîµ Apply Waivers
- Reads the cleaned JSON data.
- Cross-references findings with waiver rules in `waivers.yaml`.
- Marks matching entries as **waived** based on platform and waiver ID.

### 4. üîÅ Publish to Splunk
- Transformed and waiver-processed JSON data is sent to **Splunk** for centralized compliance tracking.

---

## ‚è∞ Automation & Scheduling

- Each stage is triggered as an **Ansible task**:
  - `download`
  - `transform`
  - `waivers`

- The tasks are scheduled in **Ansible Tower** to run automatically:

  > **Schedule:** Every **Monday at 09:00 AM (London time)**

---

## üìÅ Folder Structure

```bash
chf_data_ingestion/
‚îú‚îÄ‚îÄ source/         # Raw Excel scan reports from AWS Inspector
‚îú‚îÄ‚îÄ output/         # Cleaned and transformed JSON data
‚îú‚îÄ‚îÄ waivers.yaml    # Waiver definitions by platform and ID
‚îú‚îÄ‚îÄ playbooks/
‚îÇ   ‚îú‚îÄ‚îÄ download.yml
‚îÇ   ‚îú‚îÄ‚îÄ transform.yml
‚îÇ   ‚îî‚îÄ‚îÄ waivers.yml
‚îú‚îÄ‚îÄ README.md       # Project documentation



----
I need to validate Amazon Inspector 2 scan results against GCS-approved CIS benchmark profiles,
so that I can update waivers.yaml with the correct waiver IDs for approved rules across supported platforms.

Description
The task involves automating the comparison between scan results from Amazon Inspector 2 (which follows CIS benchmarks) and an Excel list of approved CIS rules provided by the GCS (Governance, Compliance & Security) team. The goal is to identify which findings from Inspector 2 are approved by GCS and should therefore be added to waivers.yaml under the corresponding platform.

Supported platforms include:

amazon_linux_2023

amazon_linux_2

microsoft_windows_server_2022

microsoft_windows_server_2019

rocky_rocky_linux_8

The final output is an updated waivers.yaml file that lists all approved waiver_ids under the correct platform, so they can be processed for exemption downstream.

Acceptance Criteria
Input Handling:

The script accepts:

Amazon Inspector 2 scan output (in JSON format).

GCS-approved profile list (in Excel or CSV format).

Existing waivers.yaml file.

Data Comparison:

The script matches CIS benchmark IDs (or equivalent identifiers) between the Inspector 2 scan and GCS list.

Only exact matches (by ID) are considered approved.

Platform-Specific Logic:

The comparison is scoped to the five supported platforms.

Waivers are grouped and written under their respective platform names in waivers.yaml.

YAML Update:

If waivers.yaml exists, it is updated in-place with new waiver IDs (duplicates are avoided).

If it doesn't exist, the script creates a new file with correct structure.

Validation:

The script logs:

Total number of findings scanned.

Number of approved waivers added per platform.

Any findings that did not match an approved profile.

Error Handling:

Graceful handling of malformed files, unsupported platforms, or mismatched formats.

Alerts/logs are generated for any inconsistencies.
---
Description
I need to write a Python script that reads waiver IDs from a waivers.yaml file and updates the status of matching entries in a list of JSON files,
so that the JSON files reflect which waiver checks should be marked as "waived" for specific platforms.

Acceptance Criteria
YAML Parsing:

The script correctly reads and parses waivers.yaml.

The YAML file contains platforms and lists of waiver IDs under each platform.

JSON Processing:

The script reads all .json files from a specified directory.

Each JSON file contains a list or dictionary of items, each with at least waiver_id, status, and platform fields.

Matching Logic:

For each JSON entry, if the platform matches an entry in waivers.yaml, and the waiver_id is in the corresponding waiver_id list, then update its status to "waived".

File Update:

The modified JSON data is saved back to the file or to a new file (based on configuration or prompt).

No JSON files are updated if there are no matches.

Logging & Output:

The script logs the number of updated entries per file.

Errors in reading or writing files are logged gracefully.

Error Handling:

Proper error handling is in place for missing fields, malformed JSON, or YAML syntax errors.

Test Case:

A test directory with sample JSON files and a sample waivers.yaml can be processed without errors and produces correct output.

----
import os
import json
import yaml

# Load waivers.yaml
with open("waivers.yaml", "r") as f:
    waivers = yaml.safe_load(f)

waiver_map = {}
for platform, items in waivers.items():
    for item in items:
        platform_name = item["platform"]
        waiver_ids = item.get("waivers_id", [])
        waiver_map[platform_name] = set(waiver_ids)

# Directory containing JSON files
source_dir = "sourcefiles"

# Process each JSON file
for filename in os.listdir(source_dir):
    if filename.endswith(".json"):
        filepath = os.path.join(source_dir, filename)

        with open(filepath, "r", encoding="utf-8") as f:
            try:
                data = json.load(f)
            except json.JSONDecodeError:
                print(f"Skipping invalid JSON: {filename}")
                continue

        # Check if it's a list of objects
        if isinstance(data, list):
            modified = False
            for item in data:
                platform = item.get("platform")
                check_id = item.get("id")
                if platform in waiver_map and check_id in waiver_map[platform]:
                    if item.get("status") != "skipped":
                        item["status"] = "skipped"
                        modified = True
            if modified:
                with open(filepath, "w", encoding="utf-8") as f:
                    json.dump(data, f, indent=2)
                print(f"Updated entries in: {filename}")
        else:
            print(f"Unexpected JSON format (not a list) in: {filename}")



---------------
# Calculate pipeline_name: Remove -gl if it ends with -gl
      pipeline_name = endswith(each.value.repo_name, "-gl") ? substr(each.value.repo_name, 0, length(each.value.repo_name) - 3) : each.value.repo_name

      # Calculate pipeline_identifier: Replace - with space and remove -gl if it ends with -gl
      pipeline_identifier = endswith(each.value.repo_name, "-gl") ? 
        replace(substr(each.value.repo_name, 0, length(each.value.repo_name) - 3), "-", " ") : 
        replace(each.value.repo_name, "-", " ")
---
#!/bin/bash

# Variables
VIRTUALSERVICE_NAME="vs-state-mgmt-canary-svc-svc"
NAMESPACE="<namespace>"  # Replace with your namespace

echo "Fetching VirtualService $VIRTUALSERVICE_NAME from namespace $NAMESPACE..."

# Get the VirtualService JSON
virtual_service=$(oc get virtualservice $VIRTUALSERVICE_NAME -n $NAMESPACE -o json)

if [ $? -ne 0 ]; then
  echo "Failed to fetch VirtualService. Please check the name and namespace."
  exit 1
fi

echo "Successfully fetched VirtualService. Now checking for route with 'reg-channel-version: ocp-svc-test'..."

# Find the index of the route with the ocp-svc-test header
route_index=$(echo $virtual_service | jq -r '.spec.http | to_entries[] | select(.value.match[].headers["reg-channel-version"].exact == "ocp-svc-test") | .key')

# Debugging: Print the full http section for easier visibility
echo "HTTP section of the VirtualService:"
echo $virtual_service | jq '.spec.http'

# Check if the route exists
if [ -z "$route_index" ]; then
  echo "No route found with 'reg-channel-version: ocp-svc-test' in VirtualService $VIRTUALSERVICE_NAME."
  exit 0  # Exit without error if the route doesn't exist
else
  echo "Route with 'reg-channel-version: ocp-svc-test' found at index $route_index."
  
  # Debugging: Print the exact match that will be deleted
  echo "The following route will be deleted:"
  echo $virtual_service | jq ".spec.http[$route_index]"

  # Delete the route using the identified index
  echo "Proceeding to delete the route..."
  oc patch virtualservice $VIRTUALSERVICE_NAME -n $NAMESPACE \
    --type='json' \
    -p="[{\"op\": \"remove\", \"path\": \"/spec/http/$route_index\"}]"

  if [ $? -eq 0 ]; then
    echo "Route with 'reg-channel-version: ocp-svc-test' successfully deleted from VirtualService $VIRTUALSERVICE_NAME."
  else
    echo "Failed to delete the route. Please check the output above for more details."
  fi
fi

---
#!/bin/bash

# Variables
VIRTUALSERVICE_NAME="vs-state-mgmt-canary-svc-svc"
NAMESPACE="<namespace>"  # Replace with the correct namespace

# Get the VirtualService JSON
virtual_service=$(oc get virtualservice $VIRTUALSERVICE_NAME -n $NAMESPACE -o json)

# Find the index of the route with the ocp-gc header
route_index=$(echo $virtual_service | jq -r '.spec.http | to_entries[] | select(.value.match[].headers["reg-channel-version"].exact == "ocp-gc") | .key')

# Check if the route exists
if [ -z "$route_index" ]; then
  echo "Route with 'reg-channel-version: ocp-gc' header not found in VirtualService $VIRTUALSERVICE_NAME."
  exit 1
fi

# Delete the route using the identified index
oc patch virtualservice $VIRTUALSERVICE_NAME -n $NAMESPACE \
  --type='json' \
  -p="[{\"op\": \"remove\", \"path\": \"/spec/http/$route_index\"}]"

echo "Route with 'reg-channel-version: ocp-gc' header deleted from VirtualService $VIRTUALSERVICE_NAME."

---
oc patch virtualservice vs-state-mgmt-canary-svc-svc -n default --type=json -p='[{"op": "add", "path": "/spec/http/0", "value": {"match": [{"headers": {"reg-channel-version": {"exact": "ocp-gc"}}}, {"uri": {"prefix": "/core/state-mgmt-service/v1"}}], "route": [{"destination": {"host": "iau-state-mgmt-core-service", "port": {"number": 8080}, "subset": "iau-state-mgmt-core-service-ocp-gc"}}]}}]'

---
apiVersion: batch/v1
kind: Job
metadata:
  name: remove-matcher-job
  namespace: default  # Change this if needed
  annotations:
    argocd.argoproj.io/hook: PostDelete
    argocd.argoproj.io/hook-delete-policy: HookSucceeded
spec:
  template:
    spec:
      containers:
      - name: remove-matcher
        image: bitnami/kubectl:latest  # Using a lightweight image with kubectl
        command: ["/bin/bash"]
        args:
        - -c
        - |
          #!/bin/bash

          # Define variables
          VIRTUALSERVICE_NAME="vs-state-mgmt-canary-svc-svc"
          NAMESPACE="default"
          SUBSET_NAME="iau-state-mgmt-core-service-ocp-gc"

          # Get the current VirtualService configuration
          MATCHER_INDEX=$(kubectl get virtualservice $VIRTUALSERVICE_NAME -n $NAMESPACE -o jsonpath='{range .spec.http[*]}{.route[*].destination.subset}{"\n"}{end}' | grep -n $SUBSET_NAME | cut -d: -f1)

          # Check if the matcher exists
          if [[ -n $MATCHER_INDEX ]]; then
              # Adjust index to match JSON path
              JSON_INDEX=$((MATCHER_INDEX - 1))

              # Remove the matcher
              kubectl patch virtualservice $VIRTUALSERVICE_NAME -n $NAMESPACE --type=json -p="[{'op': 'remove', 'path': '/spec/http/$JSON_INDEX'}]"
              echo "Matcher with subset '$SUBSET_NAME' has been removed."
          else
              echo "No matcher found with subset '$SUBSET_NAME'."
          fi
      restartPolicy: Never


---
openssl crl2pkcs7 -nocrl -certfile ca.crt | openssl pkcs7 -print_certs -text -noout

---

 def branchExists = sh(
                            script: """
                            curl -s -o /dev/null -w "%{http_code}" -H "Authorization: token ${GITHUB_TOKEN}" \
                            https://api.github.com/repos/${REPO_OWNER}/${REPO_NAME}/branches/${BRANCH_NAME}
                            """,
                            returnStatus: true
                        ) == 200

---
#!/bin/bash

# Actuator health endpoint (assuming it's exposed via a service)
ACTUATOR_ENDPOINT="http://your-canary-service/actuator/health"

# Polling interval (in seconds)
POLL_INTERVAL=30

# Maximum runtime (in seconds)
MAX_RUNTIME=900

# Number of requests to send in each batch
REQUEST_BATCH_SIZE=10

# Number of batches to send
TOTAL_BATCHES=5

# Function to check actuator health
check_actuator_health() {
  RESPONSE=$(curl -s $ACTUATOR_ENDPOINT)
  STATUS=$(echo $RESPONSE | grep -o '"status":"[^"]*"' | grep -o '[^"]*$')
  
  if [ "$STATUS" == "UP" ]; then
    return 0
  else
    return 1
  fi
}

# Polling loop with timer
start_time=$(date +%s)

while true; do
  echo "Checking actuator health..."
  
  if check_actuator_health; then
    echo "Actuator is up and healthy. Sending additional requests to confirm..."

    # Initialize the counter for successful batches
    successful_batches=0

    # Send additional requests in batches
    for ((batch=1; batch<=TOTAL_BATCHES; batch++)); do
      batch_successful=true

      for ((req=1; req<=REQUEST_BATCH_SIZE; req++)); do
        if ! check_actuator_health; then
          echo "Request $req in batch $batch failed. Resetting counter."
          batch_successful=false
          break
        fi
      done

      if $batch_successful; then
        echo "Batch $batch successful."
        successful_batches=$((successful_batches + 1))
      else
        successful_batches=0
        break
      fi

      # Sleep between batches if there are more batches to send
      if [ $batch -lt $TOTAL_BATCHES ]; then
        echo "Waiting $POLL_INTERVAL seconds before next batch..."
        sleep $POLL_INTERVAL
      fi
    done

    # Check if all batches were successful
    if [ $successful_batches -eq $TOTAL_BATCHES ]; then
      echo "All batches successful. Proceeding with BDD tests."
      break
    else
      echo "Some batches failed. Restarting the check."
    fi
  else
    echo "Actuator is not up yet. Waiting..."
    sleep $POLL_INTERVAL
  fi
  
  # Check elapsed time
  current_time=$(date +%s)
  elapsed_time=$((current_time - start_time))
  
  if [ $elapsed_time -ge $MAX_RUNTIME ]; then
    echo "Maximum runtime exceeded. Exiting..."
    exit 1
  fi
done

exit 0

----
post {
        success {
            script {
                // Fetch the latest commit SHA for the PR
                def response = sh(script: "curl -s -H \"Authorization: token ${env.GITHUB_TOKEN}\" https://api.github.com/repos/${env.REPO_OWNER}/${env.REPO_NAME}/pulls/${env.PR_NUMBER}", returnStdout: true).trim()
                def json = readJSON text: response
                def commitSha = json.head.sha
                
                // Update the status for the commit
                def statusPayload = """{
                    "state": "success",
                    "description": "Build succeeded",
                    "context": "continuous-integration/jenkins"
                }"""
                sh "curl -X POST -H \"Authorization: token ${env.GITHUB_TOKEN}\" -d '${statusPayload}' https://api.github.com/repos/${env.REPO_OWNER}/${env.REPO_NAME}/statuses/${commitSha}"
            }
        }
        failure {
            script {
                // Fetch the latest commit SHA for the PR
                def response = sh(script: "curl -s -H \"Authorization: token ${env.GITHUB_TOKEN}\" https://api.github.com/repos/${env.REPO_OWNER}/${env.REPO_NAME}/pulls/${env.PR_NUMBER}", returnStdout: true).trim()
                def json = readJSON text: response
                def commitSha = json.head.sha
                
                // Update the status for the commit
                def statusPayload = """{
                    "state": "failure",
                    "description": "Build failed",
                    "context": "continuous-integration/jenkins"
                }"""
                sh "curl -X POST -H \"Authorization: token ${env.GITHUB_TOKEN}\" -d '${statusPayload}' https://api.github.com/repos/${env.REPO_OWNER}/${env.REPO_NAME}/statuses/${commitSha}"
            }
        }
    }
}

---
pipeline {
    agent any
    environment {
        GITHUB_TOKEN = credentials('github-token-id') // GitHub token stored in Jenkins credentials
    }
    stages {
        stage('Fetch PR Labels') {
            steps {
                script {
                    def prNumber = env.ghprbPullId
                    def repo = 'owner/repository'
                    def response = sh(script: "curl -s -H \"Authorization: token ${env.GITHUB_TOKEN}\" -H \"Accept: application/vnd.github.v3+json\" https://api.github.com/repos/${repo}/issues/${prNumber}/labels", returnStdout: true).trim()
                    def labels = readJSON(text: response)
                    def appName = labels.find { it.name.startsWith('appname:') }?.name?.split(': ')[1]
                    def releaseName = labels.find { it.name.startsWith('releaseName:') }?.name?.split(': ')[1]
                    
                    if (!appName || !releaseName) {
                        error("Required labels not found.")
                    }
                    
                    env.ACTUATOR_ENDPOINT = "https://sitsasasasaasas/${appName}/v1.0/actuator/health"
                    env.RELEASE_NAME = releaseName
                    
                    echo "Labels for PR #${prNumber}: ${labels*.name.join(', ')}"
                    echo "ACTUATOR_ENDPOINT: ${env.ACTUATOR_ENDPOINT}"
                    echo "RELEASE_NAME: ${env.RELEASE_NAME}"
                }
            }
        }
        stage('Check Actuator Health') {
            steps {
                withCredentials([
                    file(credentialsId: 'tls-crt-id', variable: 'TLS_CRT_PATH'),
                    file(credentialsId: 'tls-key-id', variable: 'TLS_KEY_PATH')
                ]) {
                    sh """
                    chmod +x path/to/your/script.sh
                    path/to/your/script.sh \$TLS_CRT_PATH \$TLS_KEY_PATH \$ACTUATOR_ENDPOINT \$RELEASE_NAME
                    """
                }
            }
        }
        // Other stages...
    }
}

---
pipeline {
    agent any
    environment {
        GITHUB_TOKEN = credentials('github-token-id') // GitHub token stored in Jenkins credentials
    }
    stages {
        stage('Fetch PR Labels') {
            steps {
                script {
                    def prNumber = env.ghprbPullId
                    def repo = 'owner/repository'
                    def response = sh(script: "curl -s -H \"Authorization: token ${env.GITHUB_TOKEN}\" -H \"Accept: application/vnd.github.v3+json\" https://api.github.com/repos/${repo}/issues/${prNumber}/labels", returnStdout: true).trim()
                    def labels = readJSON(text: response)
                    echo "Labels for PR #${prNumber}: ${labels*.name.join(', ')}"
                }
            }
        }
        // Other stages...
    }
}

---------------------
#!/bin/bash

# Actuator health endpoint (assuming it's exposed via a service)
ACTUATOR_ENDPOINT="http://your-canary-service/actuator/health"

# Polling interval (in seconds)
POLL_INTERVAL=30

# Maximum runtime (in seconds)
MAX_RUNTIME=900

# Function to check actuator health
check_actuator_health() {
  RESPONSE=$(curl -s $ACTUATOR_ENDPOINT)
  STATUS=$(echo $RESPONSE | grep -o '"status":"[^"]*"' | grep -o '[^"]*$')
  
  if [ "$STATUS" == "UP" ]; then
    return 0
  else
    return 1
  fi
}

# Polling loop with timer
start_time=$(date +%s)

while true; do
  echo "Checking actuator health..."
  
  if check_actuator_health; then
    echo "Actuator is up and healthy."
    break
  else
    echo "Actuator is not up yet. Waiting..."
    sleep $POLL_INTERVAL
  fi
  
  # Check elapsed time
  current_time=$(date +%s)
  elapsed_time=$((current_time - start_time))
  
  if [ $elapsed_time -ge $MAX_RUNTIME ]; then
    echo "Maximum runtime exceeded. Exiting..."
    exit 1
  fi
done

echo "Canary instance is healthy. Proceeding with BDD tests."
exit 0

----------------------

pipeline {
    agent any
    environment {
        ACTUATOR_ENDPOINT = "https://your-canary-service/actuator/health"
    }
    stages {
        stage('Wait for Canary Pods') {
            steps {
                script {
                    // Fetch the certificate and key from Jenkins credentials
                    withCredentials([string(credentialsId: 'SIT_TLS_CRT', variable: 'CERT_CONTENT'),
                                     string(credentialsId: 'SIT_TLS_KEY', variable: 'KEY_CONTENT')]) {

                        // Write the certificate and key to the specified paths
                        writeFile file: 'path/tls.crt', text: CERT_CONTENT
                        writeFile file: 'path/tls.key', text: KEY_CONTENT

                        def pollScript = """
                        #!/bin/bash
                        ACTUATOR_ENDPOINT="${env.ACTUATOR_ENDPOINT}"
                        CERT_PATH="path/tls.crt"
                        KEY_PATH="path/tls.key"
                        POLL_INTERVAL=30

                        check_actuator_health() {
                            echo "Polling Actuator Endpoint: \$ACTUATOR_ENDPOINT"
                            CURL_COMMAND="curl -s --cert \$CERT_PATH --key \$KEY_PATH \$ACTUATOR_ENDPOINT"
                            echo "Formed Request: \$CURL_COMMAND"
                            RESPONSE=\$(\$CURL_COMMAND)
                            STATUS=\$(echo \$RESPONSE | grep -o '"status":"[^"]*"' | grep -o '[^"]*\$')
                            echo "Response: \$RESPONSE"
                            echo "Parsed Status: \$STATUS"
                            if [ "\$STATUS" == "UP" ]; then
                                return 0
                            else
                                return 1
                            fi
                        }

                        while true; do
                            echo "Checking actuator health..."
                            if check_actuator_health; then
                                echo "Actuator is up and healthy."
                                break
                            else
                                echo "Actuator is not up yet. Waiting..."
                                sleep \$POLL_INTERVAL
                            fi
                        done

                        echo "Canary instance is healthy. Proceeding with BDD tests."
                        exit 0
                        """
                        writeFile file: 'pollActuatorHealth.sh', text: pollScript
                        sh 'chmod +x pollActuatorHealth.sh'
                        sh './pollActuatorHealth.sh'
                    }
                }
            }
        }
        stage('Run BDD Tests') {
            steps {
                echo 'Running BDD tests...'
                // Add your steps to run BDD tests here
            }
        }
    }
}

----

#!/bin/bash
ACTUATOR_ENDPOINT="$1"
CERT_PATH="$2"
KEY_PATH="$3"
POLL_INTERVAL=30

check_actuator_health() {
    echo "Polling Actuator Endpoint: $ACTUATOR_ENDPOINT"
    CURL_COMMAND="curl -s --cert $CERT_PATH --key $KEY_PATH $ACTUATOR_ENDPOINT"
    echo "Formed Request: $CURL_COMMAND"
    RESPONSE=$($CURL_COMMAND)
    STATUS=$(echo $RESPONSE | grep -o '"status":"[^"]*"' | grep -o '[^"]*$')
    echo "Response: $RESPONSE"
    echo "Parsed Status: $STATUS"
    if [ "$STATUS" == "UP" ]; then
        return 0
    else
        return 1
    fi
}

while true; do
    echo "Checking actuator health..."
    if check_actuator_health; then
        echo "Actuator is up and healthy."
        break
    else
        echo "Actuator is not up yet. Waiting..."
        sleep $POLL_INTERVAL
    fi
done

echo "Canary instance is healthy. Proceeding with BDD tests."
exit 0

pipeline {
    agent any
    environment {
        ACTUATOR_ENDPOINT = "https://your-canary-service/actuator/health"
    }
    stages {
        stage('Wait for Canary Pods') {
            steps {
                script {
                    // Fetch the certificate and key from Jenkins credentials
                    withCredentials([string(credentialsId: 'SIT_TLS_CRT', variable: 'CERT_CONTENT'),
                                     string(credentialsId: 'SIT_TLS_KEY', variable: 'KEY_CONTENT')]) {

                        // Write the certificate and key to the specified paths
                        writeFile file: 'path/tls.crt', text: CERT_CONTENT
                        writeFile file: 'path/tls.key', text: KEY_CONTENT

                        // Write the poll script to the workspace
                        writeFile file: 'pollActuatorHealth.sh', text: libraryResource('path/to/pollActuatorHealth.sh')
                        sh 'chmod +x pollActuatorHealth.sh'

                        // Execute the poll script
                        sh './pollActuatorHealth.sh "${env.ACTUATOR_ENDPOINT}" "path/tls.crt" "path/tls.key"'
                    }
                }
            }
        }
        stage('Run BDD Tests') {
            steps {
                echo 'Running BDD tests...'
                // Add your steps to run BDD tests here
            }
        }
    }
}


----

pipeline {
    agent any
    environment {
        GITHUB_TOKEN = credentials('github-token-id') // GitHub token stored in Jenkins credentials
    }
    stages {
        stage('Fetch PR Labels') {
            steps {
                script {
                    def prNumber = env.ghprbPullId
                    def repo = 'owner/repository'
                    def response = sh(script: "curl -s -H \"Authorization: token ${env.GITHUB_TOKEN}\" -H \"Accept: application/vnd.github.v3+json\" https://api.github.com/repos/${repo}/issues/${prNumber}/labels", returnStdout: true).trim()
                    def labels = readJSON(text: response)
                    
                    // Ensure there are exactly 4 labels
                    if (labels.size() != 4) {
                        error("Expected exactly 4 labels, but found ${labels.size()}.")
                    }
                    
                    // Extract appName and releaseName from labels
                    def appNameLabel = labels.find { it.name.startsWith('appname:') }
                    def releaseNameLabel = labels.find { it.name.startsWith('releaseName:') }
                    
                    if (!appNameLabel || !releaseNameLabel) {
                        error("Required labels not found.")
                    }
                    
                    def appName = appNameLabel.name.split(': ')[1]
                    def releaseName = releaseNameLabel.name.split(': ')[1]
                    
                    // Read the YAML file
                    def appConfig = readYaml file: 'path/to/app_config.yaml'
                    def serviceConfig = appConfig.services[appName]
                    
                    // Check if appName exists in YAML
                    if (!serviceConfig) {
                        error("Appname '${appName}' not found in YAML configuration. Stopping pipeline execution.")
                    }
                    
                    def contextPath = serviceConfig.context_path
                    
                    env.ACTUATOR_ENDPOINT = "https://your-canary-service${contextPath}"
                    env.RELEASE_NAME = releaseName
                    
                    echo "Labels for PR #${prNumber}: ${labels*.name.join(', ')}"
                    echo "ACTUATOR_ENDPOINT: ${env.ACTUATOR_ENDPOINT}"
                    echo "RELEASE_NAME: ${env.RELEASE_NAME}"
                }
            }
        }
        stage('Check Actuator Health') {
            when {
                expression { return env.ACTUATOR_ENDPOINT != null }
            }
            steps {
                withCredentials([
                    file(credentialsId: 'tls-crt-id', variable: 'TLS_CRT_PATH'),
                    file(credentialsId: 'tls-key-id', variable: 'TLS_KEY_PATH')
                ]) {
                    sh """
                    chmod +x path/to/your/script.sh
                    path/to/your/script.sh \$TLS_CRT_PATH \$TLS_KEY_PATH \$ACTUATOR_ENDPOINT \$RELEASE_NAME
                    """
                }
            }
        }
        // Other stages...
    }
}



